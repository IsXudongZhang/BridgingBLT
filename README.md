# BridgingBLT: a deep learning method of bridging BiLSTM and Transformer for drug-target interactions prediction

Identification of drug-target interactions (DTIs) is crucial in several drug development applications, including lead discovery, drug repurposing, and elucidation of potential off-target or adverse effects. Computational techniques for predicting DTIs, such as molecular dynamics, quantum mechanics/molecular mechanics, and molecular docking, have low accuracy and high computational cost. Recently, many deep learning-based studies can minimize the loss of feature information by processing sequences of drugs and proteins in certain forms. Although these methods can improve the accuracy of DTIs prediction, it still has many limitations. We propose BridgingBLT, a model that bridges Transformer and bidirectional long shortterm memory (BiLSTM) to predict DTIs. Transformer block captures global features by extracting semantic relationships among sub-structures through a multi-headed attention mechanism and positional embedding. BiLSTM block can learn drug and protein sequences in both directions because sequences of molecules do not distinguish between forward and reverse. We compare with other advanced methods on three datasets and experimentally show that BridgingBLT works better. In the case study section, we use the trained BridgingBLT to recommend top-10 drugs for the functionally enriched protein Carbonic anhydrase 2 to interact with, and performed further validation by molecular docking and literature mining.

## Run

You can directly run `python train.py for training and run `python predict.py` for predicting.